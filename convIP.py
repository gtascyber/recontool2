# Author: George Tasios
# FileName: convIP.py

import re
import ipaddress
import sys


# This is how it is called from the runrecon.sh file:
# python3 convIP.py $filenamePath $fileipsPath $filesubdomainPath $fileduplicatesPath
# 1: first report file 2: extracted ips 3: extracted subdomains file 4: remove the duplicate IPs



# checks if any ip found or if in the results file contained the appropriate message generated by the amass tool which starts with "No names were discovered...."
def check_if_any_ip_found(infile):
    try:
        with open(infile, 'r') as file:
            first_line = file.readline().strip()

        if not first_line or first_line == "No names were discovered":
            print("\nNo names were discovered. No results found\n")
            exit(1)
    except Exception as e:
        print("\nError opening results file..... please try again\n")
        exit(1)


# Removes commas from the report file in order to handle more easy the content
# The report file contains a subdomain and its ips, in each line, all separated with commas
def remove_commas(file):
    with open(file, 'r') as f:
        content = f.read()
    content_with_no_commas = content.replace(',', ' ')
    with open(file, 'w') as f:
        f.write(content_with_no_commas)


# This function handles the IPs (ipv4 or ipv6) as words separated by spaces. 
# It takes from the 2nd to the last 'word' of each line and appends each one to the 'fileout' file, as a new line
def extractWords(filein, fileout):
    with open(filein, 'r') as infile, open(fileout, 'w') as outfile:
        for line in infile:
            words = line.split()
            # Extract all words except the first word
            filtered_words = words[1:]
            # Write the extracted words to the output file
            for word in filtered_words:
                outfile.write(f"{word}\n")


# This function extracts all urls (subdomains) in a file. It handles each line as words separated by spaces. 
# It takes the 1st 'word' of each line and appends it to the 'out_file', as a new line
def extract_urls(in_file, out_file):
    with open(in_file, 'r') as infile, open(out_file, 'w') as outfile:
        for line in infile:
            # Extract the url (subdomain) each line
            url = line.split(' ', 1)[0]
            # Write the URL to the output file
            outfile.write(url + '\n')


# Handles the duplicates ips and also removes local ips (ipv4 or ipv6). 
# This is committed in order to decrease the ammount of requests to the next steps.
# It uses the data structure 'set' which is actually a 'list' with unique elements. 
# If an already existed element is added, it is not added a 2nd time but rejected 
def remove_duplicate_and_private_ips(in_file, out_file):
    unique_ips = set()
    with open(in_file, 'r') as file:
        for line in file:
          ip = line.strip()
          if ip:
              unique_ips.add(ip)
    with open(out_file, 'w') as file:
        for ip in unique_ips:
            myip = ipaddress.ip_address(ip)
            if myip.is_global:
              file.write(ip + '\n')


# Counts how many IPS v4 and v6 found and prints the results. If somethinf other than an IP address found, 
# it prints an appropriate message and then stops the programm 
def count_ips(infile):
    ipv4_count = 0
    ipv6_count = 0

    with open(infile, 'r') as file:
        for line in file:
            line = line.strip()
            if line:
                try:
                    if ipaddress.IPv4Address(line):
                       ipv4_count += 1
                except ValueError:
                    try:
                        if ipaddress.IPv6Address(line):
                            ipv6_count += 1
                    except ValueError:
                        print("some lines contain nor an IPv4 neither an IPv6 address. Please check again")

    print("Found " + str(ipv4_count) + " ipv4 IPs and " + str(ipv6_count) + " ipv6 IPs")


try:
    # checks if any result occured and then run the rest scripts. If not stops the scripts
    check_if_any_ip_found(sys.argv[1])
    
    # Remove commas from the  first report file for better content handling
    remove_commas(sys.argv[1])
    
    # Extract IPv4 and IPv6 and write them to the output file
    extractWords(sys.argv[1], sys.argv[2])
    
    # Extract URLs from each line and write them to the output file
    extract_urls(sys.argv[1], sys.argv[3])
    
    # Remove duplicate ips from file iptemp.txt and write em to "ipsnoduplicates.txt"
    # Also removes non global IPs
    remove_duplicate_and_private_ips(sys.argv[2], sys.argv[4])
    
    #count final and unique ips found
    count_ips(sys.argv[4])
except Exception as e:
    print("An unexpected error occured: \n", e, "\nPlease refer to the creator of this tool\n" )
    exit(1)



print("\nFound results stored in '/report' folder\n")


